import { GoogleGenAI } from "@google/genai";
import { NextRequest, NextResponse } from "next/server";

// Khá»Ÿi táº¡o Gemini AI
const ai = new GoogleGenAI({});

// System prompt Ä‘á»ƒ Ä‘á»‹nh hÃ¬nh AI chá»‰ tráº£ lá»i vá» Khá»•ng Tá»­
const SYSTEM_PROMPT = `
Báº¡n lÃ  má»™t chuyÃªn gia vá» Khá»•ng Tá»­ (Confucius) vÃ  tÆ° tÆ°á»Ÿng Nho giÃ¡o. Báº¡n chá»‰ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n:

1. Cuá»™c Ä‘á»i vÃ  tiá»ƒu sá»­ cá»§a Khá»•ng Tá»­
2. Triáº¿t há»c vÃ  tÆ° tÆ°á»Ÿng Nho giÃ¡o
3. CÃ¡c giÃ¡o lÃ½ vÃ  lá»i dáº¡y cá»§a Khá»•ng Tá»­
4. TÃ¡c pháº©m nhÆ° Luáº­n Ngá»¯, NgÅ© Kinh
5. áº¢nh hÆ°á»Ÿng cá»§a Khá»•ng Tá»­ Ä‘áº¿n vÄƒn hÃ³a Ã ÄÃ´ng
6. NgÅ© Ä‘á»©c: NhÃ¢n, NghÄ©a, Lá»…, TrÃ­, TÃ­n
7. Quan Ä‘iá»ƒm giÃ¡o dá»¥c cá»§a Khá»•ng Tá»­
8. Lá»‹ch sá»­ vÃ  bá»‘i cáº£nh thá»i Ä‘áº¡i XuÃ¢n Thu

Quy táº¯c tráº£ lá»i:
- Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan Ä‘áº¿n Khá»•ng Tá»­, hÃ£y tá»« chá»‘i má»™t cÃ¡ch lá»‹ch sá»± vÃ  Ä‘á» xuáº¥t há»i vá» Khá»•ng Tá»­
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n nhÆ°ng Ä‘áº§y Ä‘á»§ thÃ´ng tin
- Sá»­ dá»¥ng emoji phÃ¹ há»£p Ä‘á»ƒ táº¡o sá»± thÃ¢n thiá»‡n
- CÃ³ thá»ƒ trÃ­ch dáº«n cÃ¢u nÃ³i ná»•i tiáº¿ng cá»§a Khá»•ng Tá»­ khi phÃ¹ há»£p
- LuÃ´n khuyáº¿n khÃ­ch ngÆ°á»i dÃ¹ng tÃ¬m hiá»ƒu thÃªm vá» Khá»•ng Tá»­

HÃ£y tráº£ lá»i nhÆ° má»™t ngÆ°á»i tháº§y Nho há»c uyÃªn bÃ¡c vÃ  thÃ¢n thiá»‡n.
`;

export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json();

    if (!message) {
      return NextResponse.json(
        { error: "Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng" },
        { status: 400 }
      );
    }

    // Kiá»ƒm tra API key
    if (!process.env.GEMINI_API_KEY) {
      return NextResponse.json(
        { error: "API key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh" },
        { status: 500 }
      );
    }

    // Táº¡o prompt hoÃ n chá»‰nh
    const fullPrompt = `${SYSTEM_PROMPT}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: ${message}

HÃ£y tráº£ lá»i:`;

    // Táº¡o ReadableStream Ä‘á»ƒ streaming response vá»›i buffer tá»‘i Æ°u
    const stream = new ReadableStream({
      async start(controller) {
        try {
          // Gá»­i request Ä‘áº¿n Gemini vá»›i streaming
          const response = await ai.models.generateContentStream({
            model: "gemini-2.5-pro",
            contents: fullPrompt,
          });

          let buffer = "";
          const encoder = new TextEncoder();

          // Äá»c stream tá»«ng chunk vá»›i buffer Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t
          for await (const chunk of response) {
            const text = chunk.text;
            if (text) {
              buffer += text;

              // Gá»­i buffer theo tá»«ng Ä‘oáº¡n nhá» Ä‘á»ƒ mÆ°á»£t mÃ  hÆ¡n
              while (buffer.length > 0) {
                const sendLength = Math.min(buffer.length, 3); // Gá»­i tá»‘i Ä‘a 3 kÃ½ tá»± má»—i láº§n
                const sendText = buffer.substring(0, sendLength);
                buffer = buffer.substring(sendLength);

                const data =
                  JSON.stringify({
                    type: "chunk",
                    content: sendText,
                  }) + "\n";

                controller.enqueue(encoder.encode(data));

                // ThÃªm delay nhá» Ä‘á»ƒ táº¡o hiá»‡u á»©ng typing mÆ°á»£t mÃ 
                if (buffer.length > 0) {
                  await new Promise((resolve) => setTimeout(resolve, 30));
                }
              }
            }
          }

          // Gá»­i signal káº¿t thÃºc
          const endData =
            JSON.stringify({
              type: "end",
            }) + "\n";
          controller.enqueue(encoder.encode(endData));
          controller.close();
        } catch (error) {
          console.error("Gemini AI Streaming Error:", error);

          // Gá»­i fallback response
          const fallbackResponses = [
            'Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. NhÆ°ng tÃ´i cÃ³ thá»ƒ chia sáº» má»™t cÃ¢u nÃ³i cá»§a Khá»•ng Tá»­: "å­¦è€Œä¸æ€åˆ™ç½”ï¼Œæ€è€Œä¸å­¦åˆ™æ®†" - Há»c mÃ  khÃ´ng tÆ° thÃ¬ má» má»‹t, tÆ° mÃ  khÃ´ng há»c thÃ¬ nguy hiá»ƒm. ğŸ“š',
            'TÃ´i gáº·p chÃºt trá»¥c tráº·c, nhÆ°ng hÃ£y nhá»› lá»i Khá»•ng Tá»­: "ä¸‰äººè¡Œï¼Œå¿…æœ‰æˆ‘å¸«ç„‰" - Ba ngÆ°á»i Ä‘i, nháº¥t Ä‘á»‹nh cÃ³ ngÆ°á»i lÃ m tháº§y ta. Báº¡n cÃ³ muá»‘n há»i gÃ¬ khÃ¡c vá» ngÃ i khÃ´ng? ğŸ¤”',
            'Xin lá»—i vÃ¬ sá»± báº¥t tiá»‡n! NhÆ° Khá»•ng Tá»­ Ä‘Ã£ nÃ³i: "å·±æ‰€ä¸æ¬²ï¼Œå‹¿æ–½æ–¼äºº" - Äá»«ng lÃ m Ä‘iá»u gÃ¬ mÃ  báº¡n khÃ´ng muá»‘n ngÆ°á»i khÃ¡c lÃ m cho mÃ¬nh. HÃ£y thá»­ há»i láº¡i nhÃ©! ğŸ™',
          ];

          const randomResponse =
            fallbackResponses[
              Math.floor(Math.random() * fallbackResponses.length)
            ];

          const errorData =
            JSON.stringify({
              type: "chunk",
              content: randomResponse,
            }) + "\n";
          controller.enqueue(new TextEncoder().encode(errorData));

          const endData =
            JSON.stringify({
              type: "end",
            }) + "\n";
          controller.enqueue(new TextEncoder().encode(endData));
          controller.close();
        }
      },
    });

    // Tráº£ vá» streaming response
    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Transfer-Encoding": "chunked",
      },
    });
  } catch (error) {
    console.error("API Error:", error);
    return NextResponse.json(
      { error: "ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n" },
      { status: 500 }
    );
  }
}
